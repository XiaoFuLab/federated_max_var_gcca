{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brutal-country",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-spokesman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>data_fidelity</th>\n",
       "      <th>val_fidelity</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>class_acc</th>\n",
       "      <th>lr</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  data_fidelity  val_fidelity  batch_size  class_acc     lr device\n",
       "0       0       0.001654      0.000478        1000      0.740  0.001    cpu\n",
       "1       1       0.000474      0.000494        1000      0.719  0.001    cpu\n",
       "2       2       0.000435      0.000488        1000      0.718  0.001    cpu\n",
       "3       3       0.000412      0.000498        1000      0.707  0.001    cpu\n",
       "4       4       0.000435      0.000508        1000      0.689  0.001    cpu\n",
       "5       5       0.000399      0.000497        1000      0.744  0.001    cpu\n",
       "6       6       0.000382      0.000493        1000      0.786  0.001    cpu\n",
       "7       7       0.000366      0.000486        1000      0.847  0.001    cpu\n",
       "8       8       0.000353      0.000481        1000      0.899  0.001    cpu\n",
       "9       9       0.000343      0.000479        1000      0.923  0.001    cpu\n",
       "10     10       0.000356      0.000486        1000      0.960  0.001    cpu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from dgcca.utils.run_manager import RunBuilder\n",
    "from dgcca.utils.compressor import qsgd\n",
    "from dgcca.models import g_step, DeepGCCA\n",
    "from dgcca.toy_2d.synth_data_toy_2d import create_synthData\n",
    "import pprint as pp\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Toy 2d DGCCA\")\n",
    "\n",
    "# Data\n",
    "parser.add_argument('--model_dest_alt', default='../trained_models/dgcca_toy_altmaxvar2.model', help=\"Destination model path\")\n",
    "parser.add_argument('--model_dest_cute', default='../trained_models/dgcca_toy_cutemaxvar2.model', help=\"Destination model path\")\n",
    "\n",
    "parser.add_argument('--random_seed', default=5555, help='')\n",
    "parser.add_argument('--compress', default=False, help='')\n",
    "parser.add_argument('--compression_scheme', default='qsgd', help='')\n",
    "parser.add_argument('--compress_downlink', default=True, help='')\n",
    "parser.add_argument('--batch_size', default=1000, help='')\n",
    "parser.add_argument('--lr', default=0.001, help='')\n",
    "parser.add_argument('--device', default='cpu', help='')\n",
    "parser.add_argument('--inner_epochs', default=10, help='')\n",
    "parser.add_argument('--shuffle', default=True, help='')\n",
    "parser.add_argument('--nbits', default=3, help='')\n",
    "parser.add_argument('--num_epochs', default=50, help='')\n",
    "parser.add_argument('--n_trials', default=2, help='')\n",
    "\n",
    "args = vars(parser.parse_args([]))\n",
    "pp.pprint(args)\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(int(args['random_seed']))\n",
    "\n",
    "# some special parameters\n",
    "layer_sizes_list = 3*[[128, 64, 2]]\n",
    "input_size_list = 3*[2]\n",
    "num_workers = 5\n",
    "loss_func = nn.MSELoss\n",
    "\n",
    "data_load_time = 0\n",
    "forward_time = 0\n",
    "\n",
    "device = torch.device(args['device'])\n",
    "\n",
    "acc = {'alt':np.zeros((args['n_trials'], args['num_epochs'])),\n",
    "      'cute':np.zeros((args['n_trials'], args['num_epochs']))}\n",
    "\n",
    "compress_exps = [True, False]\n",
    "\n",
    "# acc_alt = np.zeros((args['n_trials'], args['num_epochs']))\n",
    "# acc = pickle.load(open('../plt/acc_cute_toy.pkl', 'rb'))\n",
    "for compress in compress_exps:\n",
    "    args['compress'] = compress\n",
    "    if compress:\n",
    "        args['model_dest'] = args['model_dest_cute']\n",
    "    else:\n",
    "        args['model_dest'] = args['model_dest_alt']\n",
    "    for trial_id in range(args['n_trials']):\n",
    "        run_data = []\n",
    "\n",
    "        # eval and train models and copy the train params to eval\n",
    "        dgcca_train = DeepGCCA(layer_sizes_list, input_size_list)\n",
    "        dgcca_train = dgcca_train.to(device)\n",
    "        dgcca_eval = DeepGCCA(layer_sizes_list, input_size_list)\n",
    "        dgcca_eval.load_state_dict(dgcca_train.state_dict())\n",
    "\n",
    "        # Get train and validation dataset\n",
    "        train_views, train_classes = create_synthData(N=10000)\n",
    "        val_views, val_classes = create_synthData(N=2000)\n",
    "        # shuffle the dataset\n",
    "        suffler = torch.randperm(10000)\n",
    "        train_views = [view[suffler].to(device) for view in train_views]\n",
    "\n",
    "        val_shuffler = torch.randperm(2000)\n",
    "        val_views = [view[val_shuffler].to(device) for view in val_views]\n",
    "        val_classes = [classes[val_shuffler] for classes in val_classes]\n",
    "\n",
    "        optimizer = torch.optim.Adam(dgcca_train.parameters(), lr=args['lr'])\n",
    "        num_batches = len(train_views[0])//args['batch_size']\n",
    "\n",
    "        criterion = loss_func()\n",
    "        num_val_batches = len(val_views[0])//args['batch_size']\n",
    "\n",
    "        # init G\n",
    "        dgcca_eval.eval()\n",
    "        M_client = torch.stack(dgcca_eval(train_views))\n",
    "        G_server = g_step(M_client.clone().detach())  \n",
    "\n",
    "        M_serv = M_client.clone()\n",
    "        G_client = G_server.clone()\n",
    "\n",
    "        dgcca_train.train()\n",
    "\n",
    "        for epoch in range(args['num_epochs']):\n",
    "            total_dgcca_loss = 0\n",
    "            total_val_loss = 0\n",
    "            batch_count = 0\n",
    "\n",
    "            for j in range(args['inner_epochs']):\n",
    "                for i in range(num_batches):\n",
    "                    optimizer.zero_grad()\n",
    "                    batch = []\n",
    "\n",
    "                    # SGD\n",
    "\n",
    "                    batch = [view[(i*args['batch_size']):((i+1)*args['batch_size']), :] for view in train_views]            \n",
    "                    target = G_client[(i*args['batch_size']):((i+1)*args['batch_size']), :]\n",
    "\n",
    "                    # full gradient\n",
    "                    # batch = train_views\n",
    "                    # target = G\n",
    "\n",
    "                    out = torch.stack(dgcca_train(batch))  \n",
    "\n",
    "                    loss = 1/2*torch.norm(out-target)/target.shape[0]\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    total_dgcca_loss += loss.item()\n",
    "\n",
    "            ## Update G\n",
    "            dgcca_eval.load_state_dict(dgcca_train.state_dict())\n",
    "            M_client = dgcca_eval(train_views)\n",
    "            M_client = torch.stack(M_client)\n",
    "\n",
    "            if args['compress']:\n",
    "                for i in range(len(train_views)):\n",
    "                    diff = M_client[i] - M_serv[i]\n",
    "                    max_val = diff.abs().max()\n",
    "                    if args['compression_scheme'] == 'qsgd':\n",
    "                        quant = qsgd(diff, n_bits=args['nbits'])\n",
    "                    else:\n",
    "                        quant = ((1/max_val)*diff).round()*(max_val/1)    \n",
    "                    M_serv[i] = M_serv[i] + quant\n",
    "                    M_serv[i] -= M_serv[i].mean(dim=0)\n",
    "                    del max_val, diff, quant\n",
    "                    G_serv = g_step(M_serv.clone().detach())\n",
    "\n",
    "                if args['compress_downlink']:\n",
    "                    if args['compression_scheme'] == 'qsgd':\n",
    "                        G_client = G_client + qsgd(G_serv-G_client, n_bits=args['nbits'])\n",
    "                    else:\n",
    "                        # TODO: implement compression inside functions\n",
    "                        G_client = G_serv.clone()\n",
    "                else:\n",
    "                    G_client = G_serv.clone()\n",
    "            else:\n",
    "                M_client = M_client - M_client.mean(dim=1).unsqueeze(dim=1)\n",
    "                M_serv = M_client.clone()\n",
    "                G_serv = g_step(M_serv.clone().detach())  \n",
    "                G_client = G_serv.clone() \n",
    "            del M_client\n",
    "\n",
    "            # validation loss\n",
    "            out_val = torch.stack(dgcca_eval(val_views))\n",
    "            G_val = g_step(out_val.clone().detach())\n",
    "            loss_val = 1/2*torch.norm(out_val-G_val)/G_val.shape[0]\n",
    "            total_val_loss = loss_val.item()\n",
    "\n",
    "            clf = svm.LinearSVC()\n",
    "            clf.fit(G_val[:-1000,:].numpy(), val_classes[0][:-1000].numpy())\n",
    "\n",
    "            results = OrderedDict()\n",
    "            results['epoch'] = epoch\n",
    "            results['data_fidelity'] = total_dgcca_loss/(num_batches*args['inner_epochs'])\n",
    "            results['val_fidelity'] = total_val_loss\n",
    "            results['batch_size'] = args['batch_size']\n",
    "            results['class_acc'] = accuracy_score(val_classes[0][-1000:].numpy(), clf.predict(G_val[-1000:,:]))\n",
    "            results['lr'] = args['lr']\n",
    "            results['device'] = args['device']\n",
    "\n",
    "            if args['compress']:\n",
    "                acc['cute'][trial_id, epoch] = results['class_acc']\n",
    "            else:\n",
    "                acc['alt'][trial_id, epoch] = results['class_acc']\n",
    "\n",
    "            run_data.append(results)\n",
    "            df_cute = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "            clear_output(wait=True)\n",
    "            display(df_cute)\n",
    "\n",
    "            torch.save(dgcca_train, args['model_dest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afraid-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# acc = {'cute': acc_cute}\n",
    "with open('../plt/acc_cute_toy.pkl', 'wb') as f:\n",
    "    pickle.dump(acc, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rental-jimmy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 1000,\n",
      " 'compress': True,\n",
      " 'compress_downlink': True,\n",
      " 'compression_scheme': 'qsgd',\n",
      " 'device': 'cpu',\n",
      " 'inner_epochs': 10,\n",
      " 'lr': 0.001,\n",
      " 'model_dest': '../trained_models/dgcca_toy_cutemaxvar1.model',\n",
      " 'nbits': 3,\n",
      " 'num_epochs': 0,\n",
      " 'random_seed': 5555,\n",
      " 'shuffle': True}\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from dgcca.utils.run_manager import RunBuilder\n",
    "from dgcca.utils.compressor import qsgd\n",
    "from dgcca.models import g_step, DeepGCCA\n",
    "from dgcca.toy_2d.synth_data_toy_2d import create_synthData\n",
    "import pprint as pp\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Toy 2d DGCCA\")\n",
    "\n",
    "# Data\n",
    "parser.add_argument('--model_dest', default='../trained_models/dgcca_toy_cutemaxvar1.model', help=\"Destination model path\")\n",
    "parser.add_argument('--random_seed', default=5555, help='')\n",
    "parser.add_argument('--compress', default=True, help='')\n",
    "parser.add_argument('--compression_scheme', default='qsgd', help='')\n",
    "parser.add_argument('--compress_downlink', default=True, help='')\n",
    "parser.add_argument('--batch_size', default=1000, help='')\n",
    "parser.add_argument('--lr', default=0.001, help='')\n",
    "parser.add_argument('--device', default='cpu', help='')\n",
    "parser.add_argument('--inner_epochs', default=10, help='')\n",
    "parser.add_argument('--shuffle', default=True, help='')\n",
    "parser.add_argument('--nbits', default=3, help='')\n",
    "parser.add_argument('--num_epochs', default=0, help='')\n",
    "\n",
    "args = vars(parser.parse_args([]))\n",
    "pp.pprint(args)\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(int(args['random_seed']))\n",
    "\n",
    "# some special parameters\n",
    "layer_sizes_list = 3*[[128, 64, 2]]\n",
    "input_size_list = 3*[2]\n",
    "num_workers = 5\n",
    "loss_func = nn.MSELoss\n",
    "\n",
    "data_load_time = 0\n",
    "forward_time = 0\n",
    "run_data = []\n",
    "\n",
    "device = torch.device(args['device'])\n",
    "\n",
    "# eval and train models and copy the train params to eval\n",
    "dgcca_train = DeepGCCA(layer_sizes_list, input_size_list)\n",
    "dgcca_train = dgcca_train.to(device)\n",
    "dgcca_eval = DeepGCCA(layer_sizes_list, input_size_list)\n",
    "dgcca_eval.load_state_dict(dgcca_train.state_dict())\n",
    "\n",
    "# Get train and validation dataset\n",
    "train_views, train_classes = create_synthData(N=10000)\n",
    "val_views, val_classes = create_synthData(N=2000)\n",
    "# shuffle the dataset\n",
    "suffler = torch.randperm(10000)\n",
    "train_views = [view[suffler].to(device) for view in train_views]\n",
    "\n",
    "val_shuffler = torch.randperm(2000)\n",
    "val_views = [view[val_shuffler].to(device) for view in val_views]\n",
    "val_classes = [classes[val_shuffler] for classes in val_classes]\n",
    "\n",
    "optimizer = torch.optim.Adam(dgcca_train.parameters(), lr=args['lr'])\n",
    "num_batches = len(train_views[0])//args['batch_size']\n",
    "\n",
    "criterion = loss_func()\n",
    "num_val_batches = len(val_views[0])//args['batch_size']\n",
    "\n",
    "# init G\n",
    "dgcca_eval.eval()\n",
    "M_client = torch.stack(dgcca_eval(train_views))\n",
    "G_server = g_step(M_client.clone().detach())  \n",
    "\n",
    "M_serv = M_client.clone()\n",
    "G_client = G_server.clone()\n",
    "\n",
    "dgcca_train.train()\n",
    "\n",
    "for epoch in range(args['num_epochs']):\n",
    "    total_dgcca_loss = 0\n",
    "    total_val_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for j in range(args['inner_epochs']):\n",
    "        for i in range(num_batches):\n",
    "            optimizer.zero_grad()\n",
    "            batch = []\n",
    "\n",
    "            # SGD\n",
    "            batch = [view[(i*args['batch_size']):((i+1)*args['batch_size']), :] for view in train_views]            \n",
    "            target = G_client[(i*args['batch_size']):((i+1)*args['batch_size']), :]\n",
    "\n",
    "            # full gradient\n",
    "            # batch = train_views\n",
    "            # target = G\n",
    "\n",
    "            out = torch.stack(dgcca_train(batch))  \n",
    "\n",
    "            loss = 1/2*torch.norm(out-target)/target.shape[0]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_dgcca_loss += loss.item()\n",
    "\n",
    "    ## Update G\n",
    "    dgcca_eval.load_state_dict(dgcca_train.state_dict())\n",
    "    M_client = dgcca_eval(train_views)\n",
    "    M_client = torch.stack(M_client)\n",
    "\n",
    "    if args['compress']:\n",
    "        for i in range(len(train_views)):\n",
    "            diff = M_client[i] - M_serv[i]\n",
    "            max_val = diff.abs().max()\n",
    "            if args['compression_scheme'] == 'qsgd':\n",
    "                quant = qsgd(diff, n_bits=args['nbits'])\n",
    "            else:\n",
    "                quant = ((1/max_val)*diff).round()*(max_val/1)    \n",
    "            M_serv[i] = M_serv[i] + quant\n",
    "            M_serv[i] -= M_serv[i].mean(dim=0)\n",
    "            del max_val, diff, quant\n",
    "            G_serv = g_step(M_serv.clone().detach())\n",
    "        \n",
    "        if args['compress_downlink']:\n",
    "            if args['compression_scheme'] == 'qsgd':\n",
    "                G_client = G_client + qsgd(G_serv-G_client, n_bits=args['nbits'])\n",
    "            else:\n",
    "                # TODO: implement compression inside functions\n",
    "                G_client = G_serv.clone()\n",
    "        else:\n",
    "            G_client = G_serv.clone()\n",
    "    else:\n",
    "        M_client = M_client - M_client.mean(dim=1).unsqueeze(dim=1)\n",
    "        M_serv = M_client.clone()\n",
    "        G_serv = g_step(M_serv.clone().detach())  \n",
    "        G_client = G_serv.clone() \n",
    "    del M_client\n",
    "\n",
    "    # validation loss\n",
    "    out_val = torch.stack(dgcca_eval(val_views))\n",
    "    G_val = g_step(out_val.clone().detach())\n",
    "    loss_val = 1/2*torch.norm(out_val-G_val)/G_val.shape[0]\n",
    "    total_val_loss = loss_val.item()\n",
    "\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(G_val[:-1000,:].numpy(), val_classes[0][:-1000].numpy())\n",
    "\n",
    "    results = OrderedDict()\n",
    "    results['epoch'] = epoch\n",
    "    results['data_fidelity'] = total_dgcca_loss/(num_batches*args['inner_epochs'])\n",
    "    results['val_fidelity'] = total_val_loss\n",
    "    results['batch_size'] = args['batch_size']\n",
    "    results['class_acc'] = accuracy_score(val_classes[0][-1000:].numpy(), clf.predict(G_val[-1000:,:]))\n",
    "    results['lr'] = args['lr']\n",
    "    results['device'] = args['device']\n",
    "    \n",
    "    run_data.append(results)\n",
    "    df_cute_full = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "    clear_output(wait=True)\n",
    "    display(df_cute_full)\n",
    "\n",
    "    torch.save(dgcca_train, args['model_dest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "attended-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.632, 0.59 , 0.525, 0.558, 0.542, 0.586, 0.616, 0.622, 0.712,\n",
       "        0.773, 0.839, 0.887, 0.873, 0.844, 0.842, 0.853, 0.771, 0.695,\n",
       "        0.742, 0.795, 0.855, 0.861, 0.775, 0.807, 0.811, 0.864, 0.931,\n",
       "        0.93 , 0.932, 0.956, 0.958, 0.977, 0.968, 0.929, 0.918, 0.927,\n",
       "        0.926, 0.918, 0.88 , 0.903, 0.944, 0.947, 0.942, 0.943, 0.943,\n",
       "        0.931, 0.924, 0.941, 0.943, 0.942],\n",
       "       [0.599, 0.606, 0.603, 0.617, 0.641, 0.684, 0.71 , 0.81 , 0.879,\n",
       "        0.887, 0.9  , 0.942, 0.97 , 0.974, 0.959, 0.959, 0.92 , 0.942,\n",
       "        0.942, 0.961, 0.936, 0.968, 0.96 , 0.941, 0.932, 0.926, 0.926,\n",
       "        0.948, 0.964, 0.973, 0.959, 0.932, 0.929, 0.935, 0.954, 0.951,\n",
       "        0.933, 0.978, 0.985, 0.992, 0.952, 0.954, 0.975, 0.973, 0.976,\n",
       "        0.982, 0.982, 0.992, 0.992, 0.963],\n",
       "       [0.534, 0.639, 0.608, 0.539, 0.52 , 0.461, 0.477, 0.532, 0.528,\n",
       "        0.643, 0.777, 0.906, 0.931, 0.947, 0.967, 0.966, 0.971, 0.95 ,\n",
       "        0.93 , 0.928, 0.935, 0.911, 0.927, 0.964, 0.982, 0.976, 0.982,\n",
       "        0.976, 0.982, 0.988, 0.984, 0.976, 0.961, 0.951, 0.934, 0.959,\n",
       "        0.967, 0.996, 0.974, 0.966, 0.947, 0.926, 0.929, 0.944, 0.943,\n",
       "        0.938, 0.945, 0.94 , 0.95 , 0.957],\n",
       "       [0.667, 0.539, 0.632, 0.509, 0.573, 0.669, 0.838, 0.846, 0.774,\n",
       "        0.811, 0.929, 0.958, 0.933, 0.964, 0.978, 0.988, 0.976, 0.972,\n",
       "        0.987, 0.974, 0.984, 0.986, 0.988, 0.988, 0.993, 0.988, 0.98 ,\n",
       "        0.98 , 0.991, 0.994, 0.993, 0.99 , 0.984, 0.986, 0.988, 0.986,\n",
       "        0.982, 0.982, 0.986, 0.993, 0.995, 0.99 , 0.99 , 0.99 , 0.979,\n",
       "        0.965, 0.99 , 0.995, 0.997, 0.996],\n",
       "       [0.648, 0.575, 0.634, 0.673, 0.726, 0.72 , 0.701, 0.791, 0.855,\n",
       "        0.866, 0.752, 0.883, 0.886, 0.924, 0.974, 0.971, 0.975, 0.976,\n",
       "        0.98 , 0.975, 0.975, 0.979, 0.98 , 0.98 , 0.978, 0.978, 0.978,\n",
       "        0.977, 0.976, 0.986, 0.984, 0.983, 0.99 , 0.974, 0.983, 0.982,\n",
       "        0.959, 0.931, 0.962, 0.961, 0.995, 0.99 , 0.984, 0.991, 0.981,\n",
       "        0.983, 0.983, 0.984, 0.981, 0.994],\n",
       "       [0.593, 0.533, 0.557, 0.581, 0.623, 0.662, 0.748, 0.897, 0.918,\n",
       "        0.902, 0.9  , 0.936, 0.906, 0.944, 0.956, 0.96 , 0.974, 0.976,\n",
       "        0.961, 0.972, 0.932, 0.974, 0.957, 0.942, 0.927, 0.897, 0.967,\n",
       "        0.979, 0.99 , 0.96 , 0.978, 0.986, 0.994, 0.998, 0.99 , 0.984,\n",
       "        0.98 , 0.983, 0.994, 0.994, 0.993, 0.992, 0.994, 0.997, 0.986,\n",
       "        0.976, 0.981, 0.954, 0.985, 0.987],\n",
       "       [0.556, 0.665, 0.695, 0.7  , 0.893, 0.938, 0.913, 0.923, 0.943,\n",
       "        0.869, 0.934, 0.956, 0.975, 0.971, 0.974, 0.968, 0.967, 0.975,\n",
       "        0.978, 0.979, 0.969, 0.947, 0.937, 0.939, 0.961, 0.981, 0.98 ,\n",
       "        0.976, 0.978, 0.955, 0.964, 0.975, 0.984, 0.978, 0.979, 0.982,\n",
       "        0.983, 0.987, 0.983, 0.98 , 0.972, 0.985, 0.947, 0.969, 0.991,\n",
       "        0.98 , 0.967, 0.979, 0.989, 0.989],\n",
       "       [0.659, 0.727, 0.676, 0.633, 0.648, 0.705, 0.721, 0.76 , 0.813,\n",
       "        0.844, 0.862, 0.853, 0.917, 0.844, 0.89 , 0.872, 0.888, 0.891,\n",
       "        0.91 , 0.928, 0.929, 0.875, 0.934, 0.945, 0.919, 0.973, 0.969,\n",
       "        0.976, 0.977, 0.976, 0.966, 0.97 , 0.954, 0.934, 0.907, 0.896,\n",
       "        0.88 , 0.933, 0.953, 0.953, 0.934, 0.97 , 0.978, 0.966, 0.944,\n",
       "        0.886, 0.932, 0.966, 0.965, 0.978],\n",
       "       [0.582, 0.615, 0.56 , 0.578, 0.605, 0.742, 0.826, 0.862, 0.864,\n",
       "        0.894, 0.874, 0.933, 0.88 , 0.934, 0.945, 0.961, 0.932, 0.971,\n",
       "        0.947, 0.963, 0.953, 0.96 , 0.961, 0.97 , 0.956, 0.964, 0.979,\n",
       "        0.936, 0.957, 0.971, 0.968, 0.956, 0.967, 0.956, 0.973, 0.977,\n",
       "        0.958, 0.969, 0.95 , 0.976, 0.979, 0.963, 0.965, 0.936, 0.924,\n",
       "        0.929, 0.93 , 0.958, 0.933, 0.923],\n",
       "       [0.587, 0.534, 0.538, 0.55 , 0.549, 0.554, 0.568, 0.599, 0.737,\n",
       "        0.863, 0.914, 0.881, 0.853, 0.858, 0.821, 0.855, 0.868, 0.928,\n",
       "        0.928, 0.922, 0.936, 0.969, 0.962, 0.959, 0.965, 0.971, 0.983,\n",
       "        0.995, 0.967, 0.954, 0.941, 0.935, 0.924, 0.947, 0.979, 0.973,\n",
       "        0.985, 0.985, 0.983, 0.954, 0.964, 0.975, 0.986, 0.988, 0.986,\n",
       "        0.984, 0.992, 0.994, 0.986, 0.976]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc['cute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "metropolitan-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.642, 0.582, 0.601, 0.596, 0.56 , 0.663, 0.669, 0.775, 0.848,\n",
       "        0.908, 0.941, 0.885, 0.871, 0.906, 0.914, 0.926, 0.907, 0.952,\n",
       "        0.941, 0.926, 0.972, 0.946, 0.908, 0.885, 0.911, 0.93 , 0.946,\n",
       "        0.962, 0.955, 0.954, 0.907, 0.943, 0.95 , 0.962, 0.979, 0.948,\n",
       "        0.956, 0.965, 0.973, 0.982, 0.99 , 0.981, 0.972, 0.973, 0.953,\n",
       "        0.957, 0.971, 0.978, 0.94 , 0.944],\n",
       "       [0.626, 0.652, 0.704, 0.68 , 0.714, 0.756, 0.781, 0.814, 0.898,\n",
       "        0.923, 0.947, 0.94 , 0.941, 0.964, 0.963, 0.964, 0.976, 0.967,\n",
       "        0.974, 0.959, 0.961, 0.945, 0.974, 0.985, 0.969, 0.963, 0.955,\n",
       "        0.955, 0.962, 0.965, 0.967, 0.973, 0.982, 0.99 , 0.974, 0.968,\n",
       "        0.974, 0.992, 0.994, 0.994, 0.994, 0.996, 0.993, 0.988, 0.968,\n",
       "        0.968, 0.975, 0.983, 0.987, 0.984],\n",
       "       [0.6  , 0.627, 0.676, 0.715, 0.795, 0.856, 0.882, 0.89 , 0.893,\n",
       "        0.896, 0.917, 0.932, 0.944, 0.941, 0.95 , 0.952, 0.96 , 0.948,\n",
       "        0.939, 0.937, 0.93 , 0.928, 0.933, 0.948, 0.947, 0.94 , 0.939,\n",
       "        0.959, 0.862, 0.828, 0.814, 0.839, 0.813, 0.801, 0.809, 0.8  ,\n",
       "        0.818, 0.869, 0.911, 0.935, 0.95 , 0.939, 0.951, 0.972, 0.975,\n",
       "        0.976, 0.978, 0.987, 0.992, 0.998],\n",
       "       [0.711, 0.715, 0.726, 0.799, 0.857, 0.856, 0.922, 0.789, 0.815,\n",
       "        0.867, 0.83 , 0.814, 0.815, 0.843, 0.824, 0.86 , 0.914, 0.935,\n",
       "        0.951, 0.964, 0.941, 0.954, 0.991, 0.991, 0.974, 0.987, 0.994,\n",
       "        0.993, 0.991, 0.992, 0.981, 0.975, 0.977, 0.976, 0.995, 0.957,\n",
       "        0.976, 0.986, 0.99 , 0.991, 0.991, 0.993, 0.994, 0.989, 0.984,\n",
       "        0.974, 0.966, 0.979, 0.983, 0.993],\n",
       "       [0.65 , 0.591, 0.548, 0.55 , 0.629, 0.676, 0.627, 0.611, 0.794,\n",
       "        0.877, 0.924, 0.943, 0.927, 0.942, 0.92 , 0.941, 0.957, 0.953,\n",
       "        0.956, 0.959, 0.932, 0.933, 0.984, 0.981, 0.978, 0.972, 0.98 ,\n",
       "        0.981, 0.973, 0.982, 0.987, 0.978, 0.984, 0.987, 0.982, 0.974,\n",
       "        0.963, 0.982, 0.971, 0.958, 0.987, 0.981, 0.978, 0.973, 0.98 ,\n",
       "        0.98 , 0.983, 0.985, 0.988, 0.974],\n",
       "       [0.659, 0.718, 0.758, 0.773, 0.76 , 0.803, 0.891, 0.945, 0.938,\n",
       "        0.946, 0.947, 0.919, 0.94 , 0.956, 0.988, 0.961, 0.963, 0.962,\n",
       "        0.971, 0.942, 0.962, 0.968, 0.982, 0.924, 0.964, 0.973, 0.991,\n",
       "        0.983, 0.982, 0.988, 0.981, 0.982, 0.98 , 0.986, 0.967, 0.965,\n",
       "        0.971, 0.985, 0.989, 0.991, 0.988, 0.984, 0.972, 0.982, 0.98 ,\n",
       "        0.995, 0.994, 0.991, 0.993, 0.991],\n",
       "       [0.66 , 0.562, 0.623, 0.74 , 0.828, 0.84 , 0.835, 0.853, 0.85 ,\n",
       "        0.851, 0.846, 0.869, 0.915, 0.905, 0.918, 0.925, 0.918, 0.924,\n",
       "        0.952, 0.967, 0.975, 0.98 , 0.971, 0.97 , 0.96 , 0.956, 0.952,\n",
       "        0.962, 0.973, 0.963, 0.947, 0.987, 0.996, 0.995, 0.994, 0.992,\n",
       "        0.983, 0.973, 0.967, 0.973, 0.979, 0.983, 0.982, 0.973, 0.968,\n",
       "        0.961, 0.973, 0.984, 0.984, 0.98 ],\n",
       "       [0.709, 0.688, 0.735, 0.769, 0.795, 0.774, 0.788, 0.809, 0.833,\n",
       "        0.844, 0.869, 0.884, 0.89 , 0.941, 0.934, 0.923, 0.934, 0.94 ,\n",
       "        0.961, 0.981, 0.959, 0.983, 0.981, 0.991, 0.994, 0.997, 0.996,\n",
       "        0.997, 0.994, 0.983, 0.979, 0.977, 0.976, 0.975, 0.974, 0.975,\n",
       "        0.964, 0.989, 0.99 , 0.982, 0.983, 0.984, 0.987, 0.984, 0.988,\n",
       "        0.993, 0.992, 0.987, 0.99 , 0.991],\n",
       "       [0.605, 0.736, 0.802, 0.853, 0.867, 0.907, 0.917, 0.921, 0.951,\n",
       "        0.956, 0.965, 0.897, 0.937, 0.958, 0.973, 0.984, 0.987, 0.945,\n",
       "        0.974, 0.988, 0.99 , 0.979, 0.977, 0.971, 0.984, 0.995, 0.994,\n",
       "        0.991, 0.964, 0.962, 0.953, 0.967, 0.983, 0.986, 0.994, 0.991,\n",
       "        0.978, 0.978, 0.861, 0.978, 1.   , 0.999, 0.999, 0.999, 1.   ,\n",
       "        1.   , 1.   , 1.   , 0.995, 0.987],\n",
       "       [0.588, 0.597, 0.672, 0.693, 0.758, 0.793, 0.788, 0.789, 0.794,\n",
       "        0.874, 0.869, 0.954, 0.886, 0.865, 0.885, 0.899, 0.929, 0.946,\n",
       "        0.953, 0.934, 0.941, 0.949, 0.95 , 0.96 , 0.968, 0.973, 0.976,\n",
       "        0.982, 0.99 , 0.971, 0.963, 0.984, 0.987, 0.976, 0.959, 0.985,\n",
       "        0.979, 0.977, 0.976, 0.973, 0.981, 0.97 , 0.945, 0.932, 0.973,\n",
       "        0.98 , 0.975, 0.971, 0.968, 0.969]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc['alt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "underlying-dependence",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8728e470be0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcomm_cute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcomm_alt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(14,5))\n",
    "\n",
    "comm_cute = np.arange(50)*3 + 32\n",
    "comm_alt = np.arange(50)*32 + 32\n",
    "\n",
    "cute_mean = acc['cute'].mean(axis=0)\n",
    "alt_mean = acc['alt'].mean(axis=0)\n",
    "cute_std = acc['cute'].std(axis=0)\n",
    "alt_std = acc['alt'].std(axis=0)\n",
    "\n",
    "\n",
    "axes[0].plot(comm_cute, acc['cute'].mean(axis=0), linewidth=2)\n",
    "axes[0].fill_between(comm_cute, cute_mean+cute_std, cute_mean-cute_std, alpha=0.2)\n",
    "axes[0].plot(comm_alt, acc['alt'].mean(axis=0), linewidth=2)\n",
    "axes[0].fill_between(comm_alt, alt_mean+alt_std, alt_mean-alt_std, alpha=0.2)\n",
    "\n",
    "axes[0].legend(['CuteMaxVar-Deep', 'AltMaxVar-Deep'], fontsize=14)\n",
    "axes[0].set_xlabel('communication cost (BPV)', fontsize=14)\n",
    "axes[0].set_ylabel('Classification accuracy', fontsize=14)\n",
    "axes[0].set_xlim(0, 1000)\n",
    "axes[0].tick_params(axis='x', labelsize=14)\n",
    "axes[0].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "\n",
    "axes[1].plot(acc['cute'].mean(axis=0), linewidth=2)\n",
    "axes[1].fill_between(np.arange(len(cute_mean)), cute_mean+cute_std, cute_mean-cute_std, alpha=0.2)\n",
    "axes[1].plot(acc['alt'].mean(axis=0), linewidth=2)\n",
    "axes[1].fill_between(np.arange(len(alt_mean)), alt_mean+alt_std, alt_mean-alt_std, alpha=0.2)\n",
    "\n",
    "axes[1].set_xlabel('iteration', fontsize=14)\n",
    "axes[1].set_ylabel('Classification accuracy', fontsize=14)\n",
    "\n",
    "axes[1].tick_params(axis='x', labelsize=14)\n",
    "axes[1].tick_params(axis='y', labelsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "floral-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../plt/toy_class_acc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "destroyed-batman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# classification for distributed method\n",
    "clf_dist = svm.LinearSVC()\n",
    "clf_dist.fit(G_val[:-200,:].numpy(), val_classes[0][:-200].numpy())\n",
    "\n",
    "accuracy_score(val_classes[0][:-200].numpy(), clf_dist.predict(G_val[:-200,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "removable-fleet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-level",
   "metadata": {},
   "source": [
    "## Plots mini batch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sized-cocktail",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:2 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7dab7dd49c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_views\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0macc_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_clustering_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_repr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgcca_vanilla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/federated_max_var_gcca/dgcca/utils/clustering.py\u001b[0m in \u001b[0;36mget_clustering_acc\u001b[0;34m(n_clusters, gamma, random_state, latent_repr, test_classes)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_clustering_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlatent_repr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcluster_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_permutation_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/sklearn/cluster/_spectral.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0mCluster\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \"\"\"\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/sklearn/cluster/_spectral.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         X = self._validate_data(X, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 503\u001b[0;31m                                 dtype=np.float64, ensure_min_samples=2)\n\u001b[0m\u001b[1;32m    504\u001b[0m         allow_squared = self.affinity in [\"precomputed\",\n\u001b[1;32m    505\u001b[0m                                           \"precomputed_nearest_neighbors\"]\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:2 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "from dgcca.utils.clustering import *\n",
    "\n",
    "dgcca_vanilla = torch.load('../trained_models/dgcca_toy_altmaxvar.model')\n",
    "dgcca_dist = torch.load('../trained_models/dgcca_toy_cutemaxvar.model')\n",
    "\n",
    "test_views, classes = create_synthData(N=1000)\n",
    "test_views = [view.to(device) for view in test_views]\n",
    "\n",
    "\n",
    "acc_raw = []\n",
    "\n",
    "for view in test_views:\n",
    "    acc_raw.append(get_clustering_acc(n_clusters=2, gamma=5, random_state=100, latent_repr=view, test_classes=classes[0]))\n",
    "\n",
    "out1 = dgcca_vanilla(test_views)\n",
    "out1 = [a.to('cpu').detach() for a in out1]\n",
    "\n",
    "\n",
    "out1 = dgcca_vanilla(test_views)\n",
    "G_vanilla = g_step(torch.stack(out1).clone().detach())\n",
    "out1 = [a.to('cpu').detach() for a in out1]\n",
    "\n",
    "out2 = dgcca_dist(test_views)\n",
    "G_dist = g_step(torch.stack(out2).clone().detach())\n",
    "out2 = [a.to('cpu').detach() for a in out2]\n",
    "\n",
    "G_vanilla = G_vanilla.detach().to('cpu')\n",
    "vanilla_cluster_acc = get_clustering_acc(n_clusters=2, gamma=5, random_state=100, latent_repr=G_vanilla, test_classes=classes[0])\n",
    "\n",
    "G_dist = G_dist.detach().to('cpu')\n",
    "dist_cluster_acc = get_clustering_acc(n_clusters=2, gamma=5, random_state=100, latent_repr=G_dist, test_classes=classes[0])\n",
    "\n",
    "target = [t.to('cpu').detach() for t in test_views]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "covered-wrestling",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8c6583b10c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'View1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Clust. Acc. \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\" %\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4,3, figsize=(10,10))\n",
    "\n",
    "axes[0,0].set_title('Data')\n",
    "axes[0,0].scatter(target[0][:,0], target[0][:,1], c=500*[1]+500*[2])\n",
    "axes[0,0].set_ylabel('View1')\n",
    "axes[0,0].set_xlabel(\"Clust. Acc. \" + str(int(acc_raw[0]*100)) +\" %\")\n",
    "\n",
    "axes[1,0].scatter(target[1][:,0], target[1][:,1], c=500*[1]+500*[2])\n",
    "axes[1,0].set_ylabel('View2')\n",
    "axes[1,0].set_xlabel(\"Clust. Acc. \" + str(int(acc_raw[1]*100)) +\" %\")\n",
    "\n",
    "axes[2,0].scatter(target[2][:,0], target[2][:,1], c=500*[1]+500*[2])\n",
    "axes[2,0].set_ylabel('View3')\n",
    "axes[2,0].set_xlabel(\"Clust. Acc. \" + str(int(acc_raw[2]*100)) +\" %\")\n",
    "\n",
    "\n",
    "axes[0,1].set_title(\"AltMaxVar-Deep\")\n",
    "axes[0,1].scatter(out1[0][:,0], out1[0][:,1], c=500*[1]+500*[2])\n",
    "axes[1,1].scatter(out1[1][:,0], out1[1][:,1], c=500*[1]+500*[2])\n",
    "axes[2,1].scatter(out1[2][:,0], out1[2][:,1], c=500*[1]+500*[2])\n",
    "axes[3,1].set_xlabel(\"Clust. Acc. \" + str(int(vanilla_cluster_acc*100)) +\" %\")\n",
    "axes[3,1].set_title('Latent Representation ' + r'${\\mathbf{G}}$')\n",
    "axes[3,1].scatter(G_vanilla[:,0], G_vanilla[:,1], c=500*[1]+500*[2])\n",
    "\n",
    "axes[0,2].set_title(\"CuteMaxVar-Deep\")\n",
    "axes[0,2].scatter(out2[0][:,0], out2[0][:,1], c=500*[1]+500*[2])\n",
    "axes[1,2].scatter(out2[1][:,0], out2[1][:,1], c=500*[1]+500*[2])\n",
    "axes[2,2].scatter(out2[2][:,0], out2[2][:,1], c=500*[1]+500*[2])\n",
    "axes[3,2].set_xlabel(\"Clust. Acc. \" + str(int(dist_cluster_acc*100)) +\" %\")\n",
    "axes[3,2].set_title('Latent Representation ' + r'$\\widehat{\\mathbf{G}}$')\n",
    "\n",
    "axes[3,2].scatter(G_dist[:,0], G_dist[:,1], c=500*[1]+500*[2])\n",
    "\n",
    "axes[3,0].axis('off')\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        axes[i,j].set_xticks([])\n",
    "        axes[i,j].set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "documented-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../plt/toy_scatter_plot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-genealogy",
   "metadata": {},
   "source": [
    "## Classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "interracial-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla = torch.load('trained_models/dgcca_sgd_classifier.model')\n",
    "fed = torch.load('trained_models/dgcca_fed_sgd_classifier.model')\n",
    "\n",
    "train_views, train_classes = create_synthData(N=1000)\n",
    "\n",
    "train_views = [view.to(device) for view in train_views]\n",
    "\n",
    "# out1 = dgcca_vanilla(train_views)\n",
    "\n",
    "out1 = dgcca_vanilla(train_views)\n",
    "G1 = g_step(torch.stack(out1).clone().detach())\n",
    "out1 = [a.type(torch.float32).detach() for a in out1]\n",
    "\n",
    "out2 = dgcca_fed(train_views)\n",
    "G2 = g_step(torch.stack(out2).clone().detach())\n",
    "out2 = [a.type(torch.float32).detach() for a in out2]\n",
    "\n",
    "vanilla_class = []\n",
    "for i in range(3):\n",
    "    a = vanilla.model_list[i](out1[i])\n",
    "    vanilla_class.append((a.squeeze().round() - train_classes[i].to('cuda')).abs().sum())\n",
    "    \n",
    "a = vanilla.model_list[3](G1.type(torch.float32))\n",
    "vanilla_class.append((a.squeeze().round() - train_classes[0].to('cuda')).abs().sum())\n",
    "\n",
    "\n",
    "fed_class = []\n",
    "for i in range(3):\n",
    "    a = fed.model_list[i](out2[i])\n",
    "    fed_class.append((a.squeeze().round() - train_classes[i].to('cuda')).abs().sum())\n",
    "    \n",
    "a = fed.model_list[3](G2.type(torch.float32))\n",
    "fed_class.append((a.squeeze().round() - train_classes[0].to('cuda')).abs().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
